{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global path\n",
    "pre_path = \"C:\\\\Users\\\\millen11\\\\Dropbox\\\\PC\\\\Documents\\\\academia\\\\rpi\\\\classes\\\\fall23\\\\introToML\\\\introToMLapps\\\\project\\\\dataset\\\\cleaned\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>EPSI</th>\n",
       "      <th>Date</th>\n",
       "      <th>ECPI</th>\n",
       "      <th>CCPI</th>\n",
       "      <th>GSCPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greece</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>68.3</td>\n",
       "      <td>99.6</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greece</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>68.3</td>\n",
       "      <td>99.6</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greece</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>68.3</td>\n",
       "      <td>99.6</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greece</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>68.3</td>\n",
       "      <td>99.6</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greece</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>68.3</td>\n",
       "      <td>99.6</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17620</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>132.0</td>\n",
       "      <td>126.7</td>\n",
       "      <td>-1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17621</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>132.0</td>\n",
       "      <td>126.1</td>\n",
       "      <td>-1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17622</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>713.9</td>\n",
       "      <td>341.8</td>\n",
       "      <td>-1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17623</th>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>137.6</td>\n",
       "      <td>126.1</td>\n",
       "      <td>-1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17624</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>186.5</td>\n",
       "      <td>138.7</td>\n",
       "      <td>-1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17625 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Country      EPSI        Date   ECPI   CCPI  GSCPI\n",
       "0             Greece  6.000000  2010-01-31   68.3   99.6  -0.30\n",
       "1             Greece  0.000000  2010-01-31   68.3   99.6  -0.30\n",
       "2             Greece  2.000000  2010-01-31   68.3   99.6  -0.30\n",
       "3             Greece  2.611111  2010-01-31   68.3   99.6  -0.30\n",
       "4             Greece  5.000000  2010-01-31   68.3   99.6  -0.30\n",
       "...              ...       ...         ...    ...    ...    ...\n",
       "17620         Uganda       NaN  2023-03-31  132.0  126.7  -1.18\n",
       "17621         Uganda       NaN  2023-03-31  132.0  126.1  -1.18\n",
       "17622        Ukraine       NaN  2023-03-31  713.9  341.8  -1.18\n",
       "17623  United States       NaN  2023-03-31  137.6  126.1  -1.18\n",
       "17624   South Africa       NaN  2023-03-31  186.5  138.7  -1.18\n",
       "\n",
       "[17625 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Read in external facing indices\n",
    "ecpi_df = pd.read_csv(pre_path + \"ecpi_df.csv\")\n",
    "ccpi_df = pd.read_csv(pre_path + \"ccpi_df.csv\")\n",
    "epsi_df = pd.read_csv(pre_path + \"epsi_df.csv\")\n",
    "gscpi_df = pd.read_csv(pre_path + \"gscpi_df.csv\")\n",
    "\n",
    "#Merge ecpi and ccpi\n",
    "ecpi_ccpi_df = pd.merge(ecpi_df, ccpi_df, on = [\"Date\",\"Country\"], how = \"inner\")\n",
    "# display(ecpi_ccpi_df)\n",
    "\n",
    "#Merge ecpi + ccpi and epsi\n",
    "epsi_ecpi_ccpi_df = pd.merge(epsi_df, ecpi_ccpi_df, on = [\"Date\",\"Country\"], how = \"outer\")\n",
    "\n",
    "#Merge ecpi + ccpi + epsi and gscpi\n",
    "external_factors_df = pd.merge(epsi_ecpi_ccpi_df, gscpi_df, on = [\"Date\"], how = \"inner\")\n",
    "display(external_factors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sidenote: Potential contextualization of missing data points\n",
    "external_indices = pd.merge(epsi_df, ecpi_ccpi_df, on = [\"Date\",\"Country\"], how = \"outer\")\n",
    "null_df = external_indices.loc[external_indices[\"CCPI\"].isnull()]\n",
    "display(null_df)\n",
    "print(set(null_df[\"Country\"]))\n",
    "\n",
    "'''\n",
    "Based on the above data, there is 7 countries that do not have ECPI's or CCPI's in 2010. Given this, \n",
    "I believe a potential reason for this is said countries wanting to withold these consumer economic facing indices\n",
    "post recession to potentially save face. Additionally, many of these countries are oftentimes viewed as extremely stringent\n",
    "on how they're percieved and what sort of information they release. Again, there is no gurantee, that either of these things could be\n",
    "the reason for these NaNs, but just a thought.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Process and thinking for dealing with missing values in EPSI, ECPI, and CCPI. Since, I need these features to contextualize\n",
    "the market and I need data from 2010 to 2023 with as many countries as possible, to maximize scope and generality, I must find a way to\n",
    "deal with their NaN's to answer our original question (See README.md). So here's the plan:\n",
    "  1. Deal with EPSI NaNs (O1)\n",
    "    a. Fill CCPI and ECPI with future datapoints\n",
    "    b. One-hot encode\n",
    "    c. Predict EPSI\n",
    "  2. Use the newlyfound ESPI's to predict the missing CCPI and ECPI values to try to get most accurate results (O2)\n",
    "    a. One-hot encode\n",
    "    b. Predict CCPI\n",
    "    c. Predict ECPI (May benefit from CCPI being filler first, since ECPI derives from CCPI)\n",
    "  3. Repredict the EPSI values given that our 1100 rows, about 6.4 percent of our data is better represented now (O3)\n",
    "    a. One-hot encode\n",
    "    b. Predict EPSI\n",
    "    \n",
    "Although this approach is genuinely strange, I feel it is a good solution, since\n",
    "  1. The 1139/17625 rows of missing CCPI/ECPI values, is at large small. However, I would like to minimize its affect on the EPSI\n",
    "  since the EPSI values from 2021 to 2023 have more insights to bring.\n",
    "  2. Using a temporary EPSI that has minimal affect on the these decade old CCPI and ECPI values, gives a more accurate version of what the actual\n",
    "  EPSI would be like than the general mean, since environmental policy has been rapidly changing nowadays\n",
    "  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrapolate 2021 to 2023 EPSI values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = external_factors_df.drop(columns = [\"EPSI\"])\n",
    "y = external_factors_df[\"EPSI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''OP1'''\n",
    "#Filling CCPI and ECPI NaNs with neighboring rows\n",
    "null2_df = external_indices.loc[external_indices[\"EPSI\"].isnull()]\n",
    "display(null2_df)\n",
    "# X_ffill = X.fillna(method = \"ffill\", axis = 0)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_ffill, y, train_size = .7, random_state = 1)\n",
    "# Xffill_y = pd.concat([X_ffill, y], axis = 1)\n",
    "# period_to_predict = Xffill_y.loc[Xffill_y[\"EPSI\"].isnull()]\n",
    "# display(period_to_predict)\n",
    "# y_test = period_to_predict #Period of time that I want to predict the EPSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform one-hot encoding\n",
    "X_train_encoded = pd.get_dummies(X_train, columns = [\"Country\", \"Date\"])\n",
    "# display(X_train_encoded)\n",
    "X_test_encoded =  pd.get_dummies(X_test, columns = [\"Country\", \"Date\"])\n",
    "\n",
    "# Assuming 'X_train_encoded' is your DataFrame\n",
    "# Check for missing values in the X_train_encoded DataFrame\n",
    "missing_values_train = X_train_encoded.isnull()\n",
    "\n",
    "# Identify columns with missing values\n",
    "columns_with_missing_values = missing_values_train.any()\n",
    "\n",
    "# Count the number of missing values in each column\n",
    "missing_values_count_per_column = X_train_encoded.isnull().sum()\n",
    "\n",
    "# Print columns with missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(columns_with_missing_values[columns_with_missing_values].index)\n",
    "\n",
    "# Print the count of missing values in each column\n",
    "print(\"\\nNumber of missing values per column:\")\n",
    "print(missing_values_count_per_column[missing_values_count_per_column > 0])\n",
    "\n",
    "# #Temporarily fill NaN values with the mean EPSI values\n",
    "# y_train_fill = y_train.fillna(y_train.mean())\n",
    "# display(y_train_fill)\n",
    "# y_test_fill = y_test.fillna(y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_encoded, y_train_fill)\n",
    "y_pred = lin_reg.predict(X_test_encoded)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing variables and Data\n",
    "path_to_indices = \"C:\\\\Users\\\\millen11\\\\Dropbox\\\\PC\\\\Documents\\\\academia\\\\rpi\\\\classes\\\\fall23\\\\introToML\\\\introToMLapps\\\\project\\\\dataset\\\\cleaned\\\\market_indices\"\n",
    "file_pattern = \"*.csv\"\n",
    "file_paths = glob.glob(os.path.join(path_to_indices, file_pattern))\n",
    "\n",
    "for file_path in file_paths:\n",
    "  with open(file_path, \"r\") as file:\n",
    "    index_df = pd.read_csv(file_path) #Current market index i.e. S&P500\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
