{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global path\n",
    "pre_path = \"C:\\\\Users\\\\millen11\\\\Dropbox\\\\PC\\\\Documents\\\\academia\\\\rpi\\\\classes\\\\fall23\\\\introToML\\\\introToMLapps\\\\project\\\\dataset\\\\cleaned\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in external facing indices\n",
    "ecpi_df = pd.read_csv(pre_path + \"ecpi_df.csv\")\n",
    "ccpi_df = pd.read_csv(pre_path + \"ccpi_df.csv\")\n",
    "epsi_df = pd.read_csv(pre_path + \"epsi_df.csv\")\n",
    "gscpi_df = pd.read_csv(pre_path + \"gscpi_df.csv\")\n",
    "\n",
    "#Merge ecpi and ccpi\n",
    "ecpi_ccpi_df = pd.merge(ecpi_df, ccpi_df, on = [\"Date\",\"Country\"], how = \"inner\")\n",
    "display(ecpi_ccpi_df)\n",
    "\n",
    "#Merge ecpi + ccpi and epsi\n",
    "epsi_ecpi_ccpi_df = pd.merge(epsi_df, ecpi_ccpi_df, on = [\"Date\",\"Country\"], how = \"outer\")\n",
    "\n",
    "#Merge ecpi + ccpi + epsi and gscpi\n",
    "external_factors_df = pd.merge(epsi_ecpi_ccpi_df, gscpi_df, on = [\"Date\"], how = \"inner\")\n",
    "display(external_factors_df)\n",
    "# display(external_factors_df.loc[external_factors_df[\"GSCPI\"].isna()]) #confirming there are no NaNs in GSCPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sidenote: Potential contextualization of missing data points\n",
    "external_indices = pd.merge(epsi_df, ecpi_ccpi_df, on = [\"Date\",\"Country\"], how = \"outer\")\n",
    "null_df = external_indices.loc[external_indices[\"CCPI\"].isnull()]\n",
    "display(null_df)\n",
    "print(set(null_df[\"Country\"]))\n",
    "\n",
    "'''\n",
    "Based on the above data, there is 7 countries that do not have ECPI's or CCPI's in 2010. Given this, \n",
    "I believe a potential reason for this is said countries wanting to withold these consumer economic facing indices\n",
    "post recession to potentially save face. Additionally, many of these countries are oftentimes viewed as extremely stringent\n",
    "on how they're percieved and what sort of information they release. Again, there is no gurantee, that either of these things could be\n",
    "the reason for these NaNs, but just a thought.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The prediction plan --\n",
    "Process and thinking for dealing with missing values in EPSI, ECPI, and CCPI. Since, I need these features to contextualize\n",
    "the market and I need data from 2010 to 2023 with as many countries as possible, to maximize scope and generality, I must find a way to\n",
    "deal with their NaN's to answer our original question (See README.md). So here's the plan:\n",
    "  1. Deal with EPSI NaNs (O1)\n",
    "    a. Fill CCPI and ECPI with future datapoints\n",
    "    b. One-hot encode\n",
    "    c. Predict EPSI\n",
    "  2. Use the newlyfound ESPI's to predict the missing CCPI and ECPI values to try to get most accurate results (O2)\n",
    "    a. One-hot encode\n",
    "    b. Predict CCPI\n",
    "    c. Predict ECPI (May benefit from CCPI being filler first, since ECPI derives from CCPI)\n",
    "  3. Repredict the EPSI values given that our 1100 rows, about 6.4 percent of our data is better represented now (O3)\n",
    "    a. One-hot encode\n",
    "    b. Predict EPSI\n",
    "    \n",
    "Although this approach is genuinely strange, I feel it is a good solution, since\n",
    "  1. The 1139/17625 rows of missing CCPI/ECPI values, is at large small. However, I would like to minimize its affect on the EPSI\n",
    "  since the EPSI values from 2021 to 2023 have more insights to bring.\n",
    "  2. Using a temporary EPSI that has minimal affect on the these decade old CCPI and ECPI values, gives a more accurate version of what the actual\n",
    "  EPSI would be like than the general mean, since environmental policy has been rapidly changing nowadays\n",
    "\n",
    "NOTE:\n",
    "  Did not realize that EPSI also has nulls pre 2021. However, we will continue with the approach since the EPSI then will not be AS important\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing data: Data we want predicted\n",
    "predict_df = external_factors_df.loc[external_factors_df[\"EPSI\"].isna()]\n",
    "display(predict_df)\n",
    "print(set(predict_df[\"Country\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrapolate 2021 to 2023 EPSI values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "X = external_factors_df.drop(columns = [\"EPSI\"])\n",
    "y = external_factors_df[\"EPSI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find what model is best for task\n",
    "#Filling CCPI and ECPI NaN's with next row/datapoint\n",
    "X_ffill = X.fillna(method = \"ffill\", axis = 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ffill, y, train_size = .7, random_state = 1)\n",
    "\n",
    "#Perform one-hot encoding\n",
    "X_train_encoded = pd.get_dummies(X_train, columns = [\"Country\", \"Date\"])\n",
    "display(X_train_encoded)\n",
    "X_test_encoded =  pd.get_dummies(X_test, columns = [\"Country\", \"Date\"])\n",
    "\n",
    "\n",
    "#Temporarily fill NaN EPSI values with the mean EPSI values\n",
    "y_train_fill = y_train.fillna(y_train.mean())\n",
    "display(y_train_fill)\n",
    "y_test_fill = y_test.fillna(y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_encoded, y_train_fill)\n",
    "display(X_train_encoded)\n",
    "y_pred = lin_reg.predict(X_test_encoded)\n",
    "\n",
    "mse = mean_squared_error(y_test_fill, y_pred)\n",
    "print(mse)\n",
    "\n",
    "print(r2_score(y_test_fill, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the autocorrelation of EPSI to view the seasonality\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Assuming 'data' is your time series data\n",
    "Z = external_factors_df.set_index(\"Date\")\n",
    "figure, axis = plt.subplots(figsize = (12, 6))\n",
    "plot_acf(y_pred, lags = 36, ax = axis)\n",
    "plt.title(\"Autocorrelation of EPSI\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest regressor\n",
    "rfg = RandomForestRegressor(n_estimators = 100, random_state = 1)\n",
    "rfg.fit(X_train_encoded, y_train_fill)\n",
    "\n",
    "y_pred = rfg.predict(X_test_encoded)\n",
    "\n",
    "mse = mean_squared_error(y_test_fill, y_pred)\n",
    "print(mse)\n",
    "\n",
    "print(r2_score(y_test_fill, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators = 100, learning_rate = 0.1, random_state = 1)\n",
    "gbr.fit(X_train_encoded, y_train_fill)\n",
    "\n",
    "y_pred = gbr.predict(X_test_encoded)\n",
    "\n",
    "mse = mean_squared_error(y_test_fill, y_pred)\n",
    "print(mse)\n",
    "\n",
    "print(r2_score(y_test_fill, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP regressor\n",
    "mlp = MLPRegressor(max_iter = 100, random_state = 1)\n",
    "mlp.fit(X_train_encoded, y_train_fill)\n",
    "\n",
    "y_pred = mlp.predict(X_test_encoded)\n",
    "\n",
    "mse = mean_squared_error(y_test_fill, y_pred)\n",
    "print(mse)\n",
    "\n",
    "print(r2_score(y_test_fill, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since, Linear Regression has performed the best, we will use it to as our NaN prediction model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NaN(column_name:str, NaN_df: pd.DataFrame) -> pd.DataFrame: #Predicts NaN values of a given feature\n",
    "  encoded_predict_df = pd.get_dummies(NaN_df, columns = [\"Country\", \"Date\"])\n",
    "  X_predict = encoded_predict_df.drop(columns = [column_name])\n",
    "  missing_cols = set(X_train_encoded.columns) - set(X_predict.columns)\n",
    "  for col in missing_cols:\n",
    "    X_predict[col] = 0 #Add missing column with a temp, 0\n",
    "  X_predict = X_predict[X_train_encoded.columns]\n",
    "  y_pred = lin_reg.predict(X_predict)\n",
    "  predicted_df = NaN_df.copy()\n",
    "  predicted_df.loc[predicted_df[column_name].isna(), column_name] = y_pred\n",
    "  return predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_main_df(column_name: str, predicted_df: pd.DataFrame, filling_df: pd.DataFrame) -> pd.DataFrame: #Fills primary dataframe with respective features missing values\n",
    "  predicted_df = predicted_df.reset_index(drop = True)\n",
    "  filling_df_indices = filling_df[filling_df[column_name].isna()].index\n",
    "  for i, nan_index in enumerate(filling_df_indices):\n",
    "    filling_df.loc[nan_index, column_name] = predicted_df.loc[i, column_name]\n",
    "  return filling_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O1\n",
    "predicted_epsi1_df = predict_NaN(\"EPSI\", predict_df) #Predicted EPSI based on temporary ECPI and CCPI values\n",
    "# display(predicted_epsi1_df)\n",
    "\n",
    "op_df = fill_main_df(\"EPSI\", predicted_epsi1_df, external_factors_df.copy()) #Temporary version of predicted EPSI based on the prediction plan\n",
    "# display(op_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O2\n",
    "op2_df = external_factors_df[[\"CCPI\", \"ECPI\"]] \n",
    "# display(op2_df)\n",
    "restored_df = op_df.drop(columns = [\"CCPI\", \"ECPI\"])\n",
    "restored_df = pd.concat([restored_df, op2_df], axis = 1) #Dataframe with null CCPI and ECPI values and predicted EPSI values \n",
    "# display(restored_df)\n",
    "temp_df = restored_df.drop(columns = [\"CCPI\"])\n",
    "temp_ecpi_df = temp_df.fillna(method = \"ffill\", axis = 0) #Temporarily dealing with NaN ECPI values\n",
    "temp_ecpi_df = pd.concat([temp_ecpi_df, restored_df[\"CCPI\"]], axis = 1)\n",
    "temp_ecpi_df = temp_ecpi_df.rename(columns = {0: \"CCPI\"})\n",
    "# display(temp_ecpi_df)\n",
    "\n",
    "nan_CPI = temp_ecpi_df.loc[temp_ecpi_df[\"CCPI\"].isna()]\n",
    "display(nan_CPI)\n",
    "predicted_cpi_df = predict_NaN(\"CCPI\", nan_CPI) #Predicted CPI values\n",
    "\n",
    "op_df = fill_main_df(\"CCPI\", predicted_cpi_df, op_df)\n",
    "display(op_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2_df = op_df.drop(columns = [\"ECPI\"])\n",
    "restored_df = pd.concat([op2_df, op_df[\"ECPI\"]], axis = 1)\n",
    "\n",
    "nan_ECPI = restored_df.loc[restored_df[\"ECPI\"].isna()]\n",
    "# display(nan_ECPI)\n",
    "predicted_ecpi_df = predict_NaN(\"ECPI\", nan_ECPI)\n",
    "\n",
    "op_df = fill_main_df(\"ECPI\", predicted_ecpi_df, op_df)\n",
    "display(op_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O3\n",
    "op_df = op_df.drop(columns = [\"EPSI\"])\n",
    "op_df = pd.concat([op_df, external_factors_df[\"EPSI\"]], axis = 1)\n",
    "nan_EPSI = op_df.loc[op_df[\"EPSI\"].isna()]\n",
    "display(nan_EPSI)\n",
    "predicted_epsi2_df = predict_NaN(\"EPSI\", nan_EPSI)\n",
    "\n",
    "external_factors_df = fill_main_df(\"EPSI\", predicted_epsi2_df, op_df)\n",
    "display(external_factors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_factors_df.to_csv(pre_path + \"external_indic.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
